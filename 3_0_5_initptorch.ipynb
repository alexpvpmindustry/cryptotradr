{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas_ta as ta\n",
    "from multiprocessing.pool import Pool\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Symbol     Security             GICS Sector               GICS Sub-Industry  \\\n",
      "0    MMM           3M             Industrials        Industrial Conglomerates   \n",
      "1    AOS  A. O. Smith             Industrials               Building Products   \n",
      "2    ABT       Abbott             Health Care           Health Care Equipment   \n",
      "3   ABBV       AbbVie             Health Care                   Biotechnology   \n",
      "4    ACN    Accenture  Information Technology  IT Consulting & Other Services   \n",
      "\n",
      "     Headquarters Location  Date added      CIK      Founded  \n",
      "0    Saint Paul, Minnesota  1957-03-04    66740         1902  \n",
      "1     Milwaukee, Wisconsin  2017-07-26    91142         1916  \n",
      "2  North Chicago, Illinois  1957-03-04     1800         1888  \n",
      "3  North Chicago, Illinois  2012-12-31  1551152  2013 (1888)  \n",
      "4          Dublin, Ireland  2011-07-06  1467373         1989  \n"
     ]
    }
   ],
   "source": [
    "tickers = pd.read_html(\n",
    "    'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "print(tickers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 34.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(\"hist_data_2018-1-1_2023-7-12.pkl\",\"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(data[\"Open\"].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABNB\n",
      "BF.B\n",
      "BRK.B\n",
      "CARR\n",
      "CDAY\n",
      "CEG\n",
      "CTVA\n",
      "DOW\n",
      "FOX\n",
      "FOXA\n",
      "GEHC\n",
      "KVUE\n",
      "MRNA\n",
      "OTIS\n",
      "UBER\n",
      "VLTO\n"
     ]
    }
   ],
   "source": [
    "coli_with_na = np.where(np.sum(pd.isna(data[\"Close\"]))>0)[0]\n",
    "for coli in coli_with_na:\n",
    "    print(columns[coli])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opens= data[\"Open\"].drop(columns=[columns[coli] for coli in coli_with_na])\n",
    "closes = data[\"Close\"].drop(columns=[columns[coli] for coli in coli_with_na])\n",
    "# Open\tHigh\tLow\tClose\tVolume\n",
    "highs = data[\"High\"].drop(columns=[columns[coli] for coli in coli_with_na])\n",
    "lows = data[\"Low\"].drop(columns=[columns[coli] for coli in coli_with_na])\n",
    "volumes = data[\"Volume\"].drop(columns=[columns[coli] for coli in coli_with_na])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1389, 487), (1389, 487), (1389, 487), (1389, 487), (1389, 487))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opens.shape,closes.shape,highs.shape,lows.shape,volumes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker=\"TSLA\"\n",
    "training_X=[]\n",
    "training_Y=[]\n",
    "correlation_Y = []\n",
    "temp_df_full = pd.DataFrame(data={\"Open\":opens[ticker],\n",
    "                         \"High\":highs[ticker],\n",
    "                         \"Low\":lows[ticker],\n",
    "                         \"Close\":closes[ticker],\n",
    "                         \"Volume\":volumes[ticker],\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp(df,w_min,w_max):\n",
    "    return (df-w_min)/(w_max-w_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 7.53 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(\"hist_data_2018-1-1_2023-7-12_3_0_2.pkl\",\"rb\") as f:\n",
    "    [training_X,training_Y,correlation_Y] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((66232, 14), (66232,), (66232,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_X.shape,training_Y.shape,correlation_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 52931, 1: 7168, 2: 6133})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.02\n",
    "train_data_y_discrete = np.asarray(list(map(lambda x: 2 if (x>threshold) else (1 if x<-threshold else 0),training_Y)))\n",
    "Counter(train_data_y_discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66232"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read symbols for backtesting\n",
    "with open(\"3_0_2_data_symbols.pkl\",\"rb\") as f:\n",
    "    symbolsss = pickle.load(f)\n",
    "len(symbolsss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ENPH', 36),\n",
       " ('EQT', 35),\n",
       " ('PAYC', 35),\n",
       " ('ALGN', 34),\n",
       " ('TSLA', 34),\n",
       " ('BBWI', 33),\n",
       " ('GNRC', 33),\n",
       " ('CZR', 31),\n",
       " ('ETSY', 31),\n",
       " ('APA', 29),\n",
       " ('EPAM', 28),\n",
       " ('NVDA', 28),\n",
       " ('BX', 27),\n",
       " ('HAL', 27),\n",
       " ('MOS', 27),\n",
       " ('ON', 27),\n",
       " ('RL', 27),\n",
       " ('BLDR', 26),\n",
       " ('CTLT', 26),\n",
       " ('DVN', 26),\n",
       " ('LVS', 26),\n",
       " ('AMD', 25),\n",
       " ('HES', 25),\n",
       " ('MRO', 25),\n",
       " ('MU', 25),\n",
       " ('PODD', 25),\n",
       " ('RCL', 25),\n",
       " ('STLD', 25),\n",
       " ('WBD', 25),\n",
       " ('WYNN', 25),\n",
       " ('AXON', 24),\n",
       " ('FANG', 24),\n",
       " ('NCLH', 24),\n",
       " ('PCG', 24),\n",
       " ('TER', 24),\n",
       " ('ZION', 24),\n",
       " ('AMAT', 23),\n",
       " ('DHI', 23),\n",
       " ('IVZ', 23),\n",
       " ('MHK', 23),\n",
       " ('PHM', 23),\n",
       " ('ALB', 22),\n",
       " ('CCL', 22),\n",
       " ('CF', 22),\n",
       " ('FSLR', 22),\n",
       " ('LEN', 22),\n",
       " ('LRCX', 22),\n",
       " ('NFLX', 22),\n",
       " ('PARA', 22),\n",
       " ('STX', 22),\n",
       " ('URI', 22),\n",
       " ('WDC', 22),\n",
       " ('BKR', 21),\n",
       " ('KLAC', 21),\n",
       " ('MTCH', 21),\n",
       " ('NUE', 21),\n",
       " ('ODFL', 21),\n",
       " ('SLB', 21),\n",
       " ('SWKS', 21),\n",
       " ('BBY', 20),\n",
       " ('GE', 20),\n",
       " ('MOH', 20),\n",
       " ('OXY', 20),\n",
       " ('PXD', 20),\n",
       " ('VTRS', 20),\n",
       " ('APTV', 19),\n",
       " ('BWA', 19),\n",
       " ('CTRA', 19),\n",
       " ('IDXX', 19),\n",
       " ('KMX', 19),\n",
       " ('MCHP', 19),\n",
       " ('MGM', 19),\n",
       " ('MPWR', 19),\n",
       " ('ROK', 19),\n",
       " ('SYF', 19),\n",
       " ('TPR', 19),\n",
       " ('TSCO', 19),\n",
       " ('WHR', 19),\n",
       " ('ANET', 18),\n",
       " ('CMA', 18),\n",
       " ('DXCM', 18),\n",
       " ('F', 18),\n",
       " ('FTNT', 18),\n",
       " ('LYB', 18),\n",
       " ('MSCI', 18),\n",
       " ('NVR', 18),\n",
       " ('TGT', 18),\n",
       " ('UAL', 18),\n",
       " ('BA', 17),\n",
       " ('CNC', 17),\n",
       " ('DFS', 17),\n",
       " ('DLR', 17),\n",
       " ('DLTR', 17),\n",
       " ('DVA', 17),\n",
       " ('EOG', 17),\n",
       " ('FCX', 17),\n",
       " ('HPE', 17),\n",
       " ('ILMN', 17),\n",
       " ('IR', 17),\n",
       " ('JBL', 17),\n",
       " ('NOW', 17),\n",
       " ('NXPI', 17),\n",
       " ('POOL', 17),\n",
       " ('QCOM', 17),\n",
       " ('QRVO', 17),\n",
       " ('ZBRA', 17),\n",
       " ('AAL', 16),\n",
       " ('ADSK', 16),\n",
       " ('BALL', 16),\n",
       " ('CDNS', 16),\n",
       " ('CMCSA', 16),\n",
       " ('CRL', 16),\n",
       " ('EQIX', 16),\n",
       " ('GOOG', 16),\n",
       " ('INTU', 16),\n",
       " ('KIM', 16),\n",
       " ('LYV', 16),\n",
       " ('MAS', 16),\n",
       " ('MLM', 16),\n",
       " ('PFG', 16),\n",
       " ('PYPL', 16),\n",
       " ('REGN', 16),\n",
       " ('RVTY', 16),\n",
       " ('TAP', 16),\n",
       " ('TRGP', 16),\n",
       " ('TRMB', 16),\n",
       " ('VRTX', 16),\n",
       " ('VTR', 16),\n",
       " ('AMZN', 15),\n",
       " ('BG', 15),\n",
       " ('CBRE', 15),\n",
       " ('CE', 15),\n",
       " ('CRM', 15),\n",
       " ('DE', 15),\n",
       " ('EFX', 15),\n",
       " ('GEN', 15),\n",
       " ('GLW', 15),\n",
       " ('HPQ', 15),\n",
       " ('INCY', 15),\n",
       " ('INTC', 15),\n",
       " ('JNPR', 15),\n",
       " ('LULU', 15),\n",
       " ('NWSA', 15),\n",
       " ('PANW', 15),\n",
       " ('PH', 15),\n",
       " ('PLD', 15),\n",
       " ('PSX', 15),\n",
       " ('SCHW', 15),\n",
       " ('SWK', 15),\n",
       " ('TECH', 15),\n",
       " ('TTWO', 15),\n",
       " ('ULTA', 15),\n",
       " ('WAB', 15),\n",
       " ('WBA', 15),\n",
       " ('WELL', 15),\n",
       " ('WFC', 15),\n",
       " ('WST', 15),\n",
       " ('AAPL', 14),\n",
       " ('AVGO', 14),\n",
       " ('BIIB', 14),\n",
       " ('BXP', 14),\n",
       " ('CAH', 14),\n",
       " ('COP', 14),\n",
       " ('EBAY', 14),\n",
       " ('EXPE', 14),\n",
       " ('GM', 14),\n",
       " ('GOOGL', 14),\n",
       " ('HST', 14),\n",
       " ('HWM', 14),\n",
       " ('IPG', 14),\n",
       " ('JBHT', 14),\n",
       " ('MKTX', 14),\n",
       " ('PTC', 14),\n",
       " ('RF', 14),\n",
       " ('ROL', 14),\n",
       " ('SNPS', 14),\n",
       " ('SPG', 14),\n",
       " ('VFC', 14),\n",
       " ('VMC', 14),\n",
       " ('WRK', 14),\n",
       " ('ANSS', 13),\n",
       " ('AVB', 13),\n",
       " ('CI', 13),\n",
       " ('DAL', 13),\n",
       " ('DPZ', 13),\n",
       " ('EL', 13),\n",
       " ('ELV', 13),\n",
       " ('ETN', 13),\n",
       " ('IFF', 13),\n",
       " ('IP', 13),\n",
       " ('ISRG', 13),\n",
       " ('LUV', 13),\n",
       " ('MMM', 13),\n",
       " ('MPC', 13),\n",
       " ('NTRS', 13),\n",
       " ('PFE', 13),\n",
       " ('PKG', 13),\n",
       " ('ROST', 13),\n",
       " ('VLO', 13),\n",
       " ('AEP', 12),\n",
       " ('BEN', 12),\n",
       " ('BIO', 12),\n",
       " ('CDW', 12),\n",
       " ('CHTR', 12),\n",
       " ('COF', 12),\n",
       " ('CSGP', 12),\n",
       " ('DRI', 12),\n",
       " ('EMN', 12),\n",
       " ('FICO', 12),\n",
       " ('FLT', 12),\n",
       " ('FRT', 12),\n",
       " ('GPN', 12),\n",
       " ('GWW', 12),\n",
       " ('HUM', 12),\n",
       " ('LHX', 12),\n",
       " ('LOW', 12),\n",
       " ('MAR', 12),\n",
       " ('MET', 12),\n",
       " ('NDSN', 12),\n",
       " ('NEM', 12),\n",
       " ('NTAP', 12),\n",
       " ('O', 12),\n",
       " ('OKE', 12),\n",
       " ('PGR', 12),\n",
       " ('SRE', 12),\n",
       " ('STE', 12),\n",
       " ('STZ', 12),\n",
       " ('TXT', 12),\n",
       " ('WMB', 12),\n",
       " ('AES', 11),\n",
       " ('AIG', 11),\n",
       " ('AKAM', 11),\n",
       " ('AMT', 11),\n",
       " ('AXP', 11),\n",
       " ('BAX', 11),\n",
       " ('CAT', 11),\n",
       " ('CHRW', 11),\n",
       " ('CINF', 11),\n",
       " ('DHR', 11),\n",
       " ('EIX', 11),\n",
       " ('FFIV', 11),\n",
       " ('HAS', 11),\n",
       " ('HBAN', 11),\n",
       " ('HLT', 11),\n",
       " ('IRM', 11),\n",
       " ('KEY', 11),\n",
       " ('LDOS', 11),\n",
       " ('LW', 11),\n",
       " ('MCO', 11),\n",
       " ('META', 11),\n",
       " ('MSI', 11),\n",
       " ('MTB', 11),\n",
       " ('SBAC', 11),\n",
       " ('SO', 11),\n",
       " ('TDG', 11),\n",
       " ('TFC', 11),\n",
       " ('TT', 11),\n",
       " ('TYL', 11),\n",
       " ('VICI', 11),\n",
       " ('VRSN', 11),\n",
       " ('WY', 11),\n",
       " ('ADBE', 10),\n",
       " ('ADI', 10),\n",
       " ('ALLE', 10),\n",
       " ('AOS', 10),\n",
       " ('APH', 10),\n",
       " ('AZO', 10),\n",
       " ('BKNG', 10),\n",
       " ('C', 10),\n",
       " ('COST', 10),\n",
       " ('DG', 10),\n",
       " ('EQR', 10),\n",
       " ('EW', 10),\n",
       " ('EXR', 10),\n",
       " ('FAST', 10),\n",
       " ('HCA', 10),\n",
       " ('HD', 10),\n",
       " ('IEX', 10),\n",
       " ('INVH', 10),\n",
       " ('IQV', 10),\n",
       " ('IT', 10),\n",
       " ('KEYS', 10),\n",
       " ('LH', 10),\n",
       " ('LLY', 10),\n",
       " ('MO', 10),\n",
       " ('MTD', 10),\n",
       " ('PEAK', 10),\n",
       " ('PPL', 10),\n",
       " ('PWR', 10),\n",
       " ('REG', 10),\n",
       " ('RJF', 10),\n",
       " ('SJM', 10),\n",
       " ('SNA', 10),\n",
       " ('SYY', 10),\n",
       " ('TJX', 10),\n",
       " ('TMO', 10),\n",
       " ('UHS', 10),\n",
       " ('WAT', 10),\n",
       " ('XRAY', 10),\n",
       " ('ACN', 9),\n",
       " ('AMGN', 9),\n",
       " ('BMY', 9),\n",
       " ('BR', 9),\n",
       " ('CAG', 9),\n",
       " ('CFG', 9),\n",
       " ('CLX', 9),\n",
       " ('CMI', 9),\n",
       " ('CPB', 9),\n",
       " ('CPT', 9),\n",
       " ('CVS', 9),\n",
       " ('DOV', 9),\n",
       " ('EMR', 9),\n",
       " ('EXC', 9),\n",
       " ('EXPD', 9),\n",
       " ('FDS', 9),\n",
       " ('FDX', 9),\n",
       " ('FMC', 9),\n",
       " ('GILD', 9),\n",
       " ('GL', 9),\n",
       " ('GRMN', 9),\n",
       " ('GS', 9),\n",
       " ('HSIC', 9),\n",
       " ('HUBB', 9),\n",
       " ('JCI', 9),\n",
       " ('KR', 9),\n",
       " ('MS', 9),\n",
       " ('NKE', 9),\n",
       " ('NRG', 9),\n",
       " ('NSC', 9),\n",
       " ('NWS', 9),\n",
       " ('ORCL', 9),\n",
       " ('ORLY', 9),\n",
       " ('PAYX', 9),\n",
       " ('PNR', 9),\n",
       " ('PPG', 9),\n",
       " ('PRU', 9),\n",
       " ('PSA', 9),\n",
       " ('RHI', 9),\n",
       " ('RMD', 9),\n",
       " ('RTX', 9),\n",
       " ('STT', 9),\n",
       " ('TDY', 9),\n",
       " ('UDR', 9),\n",
       " ('UNH', 9),\n",
       " ('XEL', 9),\n",
       " ('XOM', 9),\n",
       " ('XYL', 9),\n",
       " ('ZTS', 9),\n",
       " ('A', 8),\n",
       " ('AMP', 8),\n",
       " ('AWK', 8),\n",
       " ('CB', 8),\n",
       " ('CCI', 8),\n",
       " ('CMG', 8),\n",
       " ('COO', 8),\n",
       " ('CTAS', 8),\n",
       " ('EA', 8),\n",
       " ('EG', 8),\n",
       " ('ESS', 8),\n",
       " ('ETR', 8),\n",
       " ('FI', 8),\n",
       " ('FITB', 8),\n",
       " ('FTV', 8),\n",
       " ('GIS', 8),\n",
       " ('HIG', 8),\n",
       " ('HII', 8),\n",
       " ('HON', 8),\n",
       " ('J', 8),\n",
       " ('K', 8),\n",
       " ('KDP', 8),\n",
       " ('KMI', 8),\n",
       " ('MA', 8),\n",
       " ('MCK', 8),\n",
       " ('MNST', 8),\n",
       " ('MSFT', 8),\n",
       " ('NDAQ', 8),\n",
       " ('NI', 8),\n",
       " ('PNC', 8),\n",
       " ('PNW', 8),\n",
       " ('SHW', 8),\n",
       " ('SPGI', 8),\n",
       " ('TMUS', 8),\n",
       " ('TROW', 8),\n",
       " ('TRV', 8),\n",
       " ('TSN', 8),\n",
       " ('TXN', 8),\n",
       " ('WEC', 8),\n",
       " ('ABBV', 7),\n",
       " ('ABT', 7),\n",
       " ('AIZ', 7),\n",
       " ('ALL', 7),\n",
       " ('ARE', 7),\n",
       " ('BAC', 7),\n",
       " ('BLK', 7),\n",
       " ('BSX', 7),\n",
       " ('CBOE', 7),\n",
       " ('CMS', 7),\n",
       " ('CNP', 7),\n",
       " ('COR', 7),\n",
       " ('CPRT', 7),\n",
       " ('CVX', 7),\n",
       " ('DD', 7),\n",
       " ('DGX', 7),\n",
       " ('DTE', 7),\n",
       " ('DUK', 7),\n",
       " ('ECL', 7),\n",
       " ('ED', 7),\n",
       " ('EVRG', 7),\n",
       " ('FIS', 7),\n",
       " ('GPC', 7),\n",
       " ('HRL', 7),\n",
       " ('JKHY', 7),\n",
       " ('KHC', 7),\n",
       " ('KMB', 7),\n",
       " ('L', 7),\n",
       " ('LKQ', 7),\n",
       " ('MAA', 7),\n",
       " ('NEE', 7),\n",
       " ('NOC', 7),\n",
       " ('OMC', 7),\n",
       " ('PEG', 7),\n",
       " ('SYK', 7),\n",
       " ('TEL', 7),\n",
       " ('UPS', 7),\n",
       " ('WTW', 7),\n",
       " ('ZBH', 7),\n",
       " ('ACGL', 6),\n",
       " ('ADM', 6),\n",
       " ('ADP', 6),\n",
       " ('AFL', 6),\n",
       " ('AMCR', 6),\n",
       " ('AON', 6),\n",
       " ('APD', 6),\n",
       " ('ATO', 6),\n",
       " ('CSCO', 6),\n",
       " ('CTSH', 6),\n",
       " ('D', 6),\n",
       " ('ES', 6),\n",
       " ('FE', 6),\n",
       " ('JNJ', 6),\n",
       " ('LIN', 6),\n",
       " ('LMT', 6),\n",
       " ('LNT', 6),\n",
       " ('MDLZ', 6),\n",
       " ('MKC', 6),\n",
       " ('PG', 6),\n",
       " ('PM', 6),\n",
       " ('ROP', 6),\n",
       " ('SBUX', 6),\n",
       " ('V', 6),\n",
       " ('VRSK', 6),\n",
       " ('WMT', 6),\n",
       " ('YUM', 6),\n",
       " ('AEE', 5),\n",
       " ('AME', 5),\n",
       " ('AVY', 5),\n",
       " ('BK', 5),\n",
       " ('BRO', 5),\n",
       " ('CHD', 5),\n",
       " ('CME', 5),\n",
       " ('CSX', 5),\n",
       " ('HOLX', 5),\n",
       " ('HSY', 5),\n",
       " ('ITW', 5),\n",
       " ('MCD', 5),\n",
       " ('MMC', 5),\n",
       " ('T', 5),\n",
       " ('TFX', 5),\n",
       " ('UNP', 5),\n",
       " ('USB', 5),\n",
       " ('WM', 5),\n",
       " ('CL', 4),\n",
       " ('DIS', 4),\n",
       " ('GD', 4),\n",
       " ('IBM', 4),\n",
       " ('ICE', 4),\n",
       " ('MRK', 4),\n",
       " ('RSG', 4),\n",
       " ('VZ', 4),\n",
       " ('AJG', 3),\n",
       " ('BDX', 3),\n",
       " ('JPM', 3),\n",
       " ('MDT', 3),\n",
       " ('PCAR', 3),\n",
       " ('PEP', 3),\n",
       " ('WRB', 3),\n",
       " ('KO', 2)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(Counter([i for i,z in zip (symbolsss,train_data_y_discrete==2) if z]).items(),key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = np.hstack([np.where(train_data_y_discrete!=0)[0],np.where(train_data_y_discrete==0)[0][::8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 7168, 2: 6133, 0: 6617})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_data_y_discrete[sel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(training_X[sel], train_data_y_discrete[sel], test_size=0.3,random_state=109,shuffle=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_X, train_data_y_discrete, test_size=0.3,random_state=109,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46362, 14), (19870, 14), (46362,), (19870,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "class MLPClassifierPyTorch(nn.Module):\n",
    "    def __init__(self, input_size, num_classes=3, weights=None, biases=None):\n",
    "        super(MLPClassifierPyTorch, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 150)\n",
    "        self.fc2 = nn.Linear(150, 150)\n",
    "        self.fc3 = nn.Linear(150, 50)\n",
    "        self.fc4 = nn.Linear(50, 10)\n",
    "        self.fc5 = nn.Linear(10, 50)\n",
    "        self.fc6 = nn.Linear(50, 150)\n",
    "        self.fc7 = nn.Linear(150, num_classes) \n",
    "        if weights is not None and biases is not None:\n",
    "            self.init_weights(weights, biases)\n",
    "\n",
    "    def init_weights(self, weights, biases):\n",
    "        layers = [self.fc1, self.fc2, self.fc3, self.fc4, self.fc5, self.fc6, self.fc7]\n",
    "\n",
    "        for i, layer in enumerate(layers):\n",
    "            layer.weight.data = torch.from_numpy(weights[i].T).float()\n",
    "            layer.bias.data = torch.from_numpy(biases[i]).float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = torch.relu(self.fc6(x))\n",
    "        x = self.fc7(x)  # No activation here, CrossEntropyLoss will apply softmax\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load(\"3_0_2_ema.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8040311013814448\n",
      "Precision: [0.80460118 0.48148148 1.        ]\n",
      "Recall: [0.99906033 0.0092264  0.00501672]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred,average=None)) \n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred,average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,\n",
       " [(14, 150), (150, 150), (150, 50), (50, 10), (10, 50), (50, 150), (150, 3)],\n",
       " [(150,), (150,), (50,), (10,), (50,), (150,), (3,)])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clf.coefs_),[c.shape for c in clf.coefs_],[c.shape for c in clf.intercepts_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.31918451e-158, -9.65730847e-002,  1.18057708e-211, ...,\n",
       "        -3.46946310e-005,  1.56089073e-073,  3.19956581e-316],\n",
       "       [-2.14673539e-165,  1.76191991e-001,  1.20355053e-221, ...,\n",
       "        -9.79403185e-005,  1.91245537e-064,  4.49804556e-315],\n",
       "       [ 8.07650427e-159,  3.11169511e-001,  6.82219337e-194, ...,\n",
       "        -2.71556253e-005,  3.74161944e-073, -5.47506355e-317],\n",
       "       ...,\n",
       "       [ 1.11273830e-178,  2.65133450e-002, -1.52798493e-180, ...,\n",
       "        -7.35497559e-005, -4.93227348e-072,  1.79889380e-315],\n",
       "       [ 3.69388067e-179, -1.06062679e-001, -1.76567368e-180, ...,\n",
       "        -6.70256476e-005,  1.95238586e-073,  4.34092920e-315],\n",
       "       [ 8.12543937e-179,  1.40344158e-002, -9.79844795e-181, ...,\n",
       "        -7.58471639e-005, -1.25272862e-071, -3.08929359e-315]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coefs_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 150)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coefs_[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66232"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_y_discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'X' and 'y' are your features and labels with shapes (1000, 14) and (1000,)\n",
    "# Convert them to PyTorch tensors\n",
    "#X = torch.tensor(training_X[sel], dtype=torch.float32)\n",
    "#y = torch.tensor(train_data_y_discrete[sel], dtype=torch.long)\n",
    "X = torch.tensor(training_X, dtype=torch.float32)\n",
    "y = torch.tensor(train_data_y_discrete, dtype=torch.long)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15,shuffle=True)\n",
    "\n",
    "# Create DataLoader for training and testing sets\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 150#128*4\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "input_size = 14\n",
    "model = MLPClassifierPyTorch(input_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 - Precision: 0.80, Recall: 1.00\n",
      "Class 1 - Precision: 0.00, Recall: 0.00\n",
      "Class 2 - Precision: 0.00, Recall: 0.00\n",
      "CPU times: total: 203 ms\n",
      "Wall time: 677 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Evaluation\n",
    "model.eval()\n",
    "#clf2.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate precision and recall for each class\n",
    "precision = precision_score(all_labels, all_predictions, average=None,zero_division=0)\n",
    "recall = recall_score(all_labels, all_predictions, average=None,zero_division=0)\n",
    "\n",
    "# Print precision and recall for each class\n",
    "for i in range(len(precision)):\n",
    "    print(f'Class {i} - Precision: {precision[i]:.2f}, Recall: {recall[i]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  0.76, 1  0.56, 2  0.35, 3  0.51, 4  0.54, CPU times: total: 4.3 s\n",
      "Wall time: 22.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training loop\n",
    "loss_history = []\n",
    "for epoch in range(5):\n",
    "    print(epoch,end=\" \")\n",
    "    avg_loss = []\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        avg_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_history.append(np.mean(avg_loss))\n",
    "    print(f\" {loss.item():.2f},\",end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150, 14])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = MLPClassifierPyTorch(input_size,weights=clf.coefs_,biases=clf.intercepts_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.31918451e-158, -9.65730847e-002,  1.18057708e-211,\n",
       "        -1.35113540e-315, -1.34110388e-001],\n",
       "       [-2.14673539e-165,  1.76191991e-001,  1.20355053e-221,\n",
       "        -2.58060042e-315,  1.96140570e-001],\n",
       "       [ 8.07650427e-159,  3.11169511e-001,  6.82219337e-194,\n",
       "        -3.31106763e-315,  3.12865980e-001],\n",
       "       [ 3.93396300e-165,  1.97469469e-001, -7.98792708e-219,\n",
       "         2.34000081e-315,  3.32819354e-001],\n",
       "       [ 3.10864982e-168,  1.93137983e-001, -1.79049559e-171,\n",
       "        -4.12780022e-315,  1.73609145e-001]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coefs_[0][:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, -0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0966,  0.1762,  0.3112,  0.1975,  0.1931],\n",
       "        [ 0.0000,  0.0000,  0.0000, -0.0000, -0.0000],\n",
       "        [-0.0000, -0.0000, -0.0000,  0.0000, -0.0000],\n",
       "        [-0.1341,  0.1961,  0.3129,  0.3328,  0.1736]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fc1.weight.data[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 - Precision: 0.805, Recall: 0.999\n",
      "Class 1 - Precision: 0.481, Recall: 0.009\n",
      "Class 2 - Precision: 1.000, Recall: 0.005\n",
      "CPU times: total: 422 ms\n",
      "Wall time: 756 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Evaluation \n",
    "clf2.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = clf2(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate precision and recall for each class\n",
    "precision = precision_score(all_labels, all_predictions, average=None,zero_division=0)\n",
    "recall = recall_score(all_labels, all_predictions, average=None,zero_division=0)\n",
    "\n",
    "# Print precision and recall for each class\n",
    "for i in range(len(precision)):\n",
    "    print(f'Class {i} - Precision: {precision[i]:.3f}, Recall: {recall[i]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(clf2, '3_0_5_pytorch_clf.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(clf2.state_dict(), '3_0_5_pytorch_clf_state.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## running on gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X = torch.tensor(training_X, dtype=torch.float32).to(device)\n",
    "y = torch.tensor(train_data_y_discrete, dtype=torch.long).to(device)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, shuffle=True)\n",
    "\n",
    "# Create DataLoader for training and testing sets\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 2000\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model and move it to the selected device\n",
    "input_size = 14\n",
    "model = MLPClassifierPyTorch(input_size).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 1.0, 30.0]).to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  0.68, 1  0.66, 2  0.64, 3  0.63, 4  0.65, 5  0.63, 6  0.58, 7  0.69, 8  0.67, 9  0.62, 10  0.60, 11  0.62, 12  0.64, 13  0.69, 14  0.69, 15  0.60, 16  0.67, 17  0.60, 18  0.68, 19  0.67, 20  0.70, 21  0.61, 22  0.66, 23  0.64, 24  0.66, 25  0.61, 26  0.62, 27  0.61, 28  0.58, 29  0.61, 30  0.60, 31  0.66, 32  0.68, 33  0.69, 34  0.68, 35  0.62, 36  0.61, 37  0.71, 38  0.63, 39  0.62, 40  0.68, 41  0.63, 42  0.61, 43  0.61, 44  0.69, 45  0.69, 46  0.67, 47  0.65, 48  0.61, 49  0.68, 50  0.62, 51  0.56, 52  0.71, 53  0.64, 54  0.63, 55  0.61, 56  0.64, 57  0.61, 58  0.63, 59  0.67, 60  0.61, 61  0.61, 62  0.62, 63  0.63, 64  0.65, 65  0.61, 66  0.68, 67  0.64, 68  0.59, 69  0.63, 70  0.62, 71  0.67, 72  0.60, 73  0.67, 74  0.65, 75  0.65, 76  0.66, 77  0.63, 78  0.60, 79  0.61, 80  0.63, 81  0.66, 82  0.65, 83  0.65, 84  0.65, 85  0.63, 86  0.66, 87  0.60, 88  0.62, 89  0.63, 90  0.64, 91  0.65, 92  0.61, 93  0.64, 94  0.65, 95  0.60, 96  0.64, 97  0.59, 98  0.68, 99  0.62, 100  0.57, 101  0.68, 102  0.61, 103  0.61, 104  0.62, 105  0.68, 106  0.62, 107  0.64, 108  0.58, 109  0.64, 110  0.66, 111  0.62, 112  0.65, 113  0.64, 114  0.66, 115  0.61, 116  0.62, 117  0.62, 118  0.69, 119  0.68, 120  0.63, 121  0.62, 122  0.66, 123  0.62, 124  0.65, 125  0.67, 126  0.61, 127  0.60, 128  0.59, 129  0.61, 130  0.62, 131  0.58, 132  0.64, 133  0.65, 134  0.61, 135  0.68, 136  0.61, 137  0.64, 138  0.62, 139  0.62, 140  0.70, 141  0.58, 142  0.61, 143  0.67, 144  0.62, 145  0.60, 146  0.59, 147  0.65, 148  0.63, 149  0.61, 150  0.69, 151  0.66, 152  0.62, 153  0.65, 154  0.65, 155  0.63, 156  0.59, 157  0.66, 158  0.59, 159  0.62, 160  0.64, 161  0.62, 162  0.64, 163  0.62, 164  0.56, 165  0.60, 166  0.66, 167  0.62, 168  0.60, 169  0.63, 170  0.64, 171  0.60, 172  0.60, 173  0.65, 174  0.65, 175  0.67, 176  0.62, 177  0.66, 178  0.59, 179  0.59, 180  0.65, 181  0.60, 182  0.65, 183  0.65, 184  0.61, 185  0.63, 186  0.65, 187  0.66, 188  0.63, 189  0.61, 190  0.60, 191  0.64, 192  0.61, 193  0.61, 194  0.63, 195  0.64, 196  0.62, 197  0.63, 198  0.64, 199  0.65, 200  0.61, 201  0.60, 202  0.63, 203  0.63, 204  0.63, 205  0.71, 206  0.65, 207  0.64, 208  0.61, 209  0.65, 210  0.67, 211  0.61, 212  0.62, 213  0.61, 214  0.55, 215  0.59, 216  0.62, 217  0.63, 218  0.63, 219  0.60, 220  0.60, 221  0.66, 222  0.64, 223  0.62, 224  0.61, 225  0.61, 226  0.58, 227  0.63, 228  0.61, 229  0.66, 230  0.69, 231  0.64, 232  0.62, 233  0.69, 234  0.61, 235  0.61, 236  0.63, 237  0.62, 238  0.69, 239  0.63, 240  0.62, 241  0.66, 242  0.63, 243  0.67, 244  0.64, 245  0.64, 246  0.66, 247  0.68, 248  0.59, 249  0.63, CPU times: total: 3min 8s\n",
      "Wall time: 7min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training loop\n",
    "loss_history = []\n",
    "for epoch in range(250):\n",
    "    print(epoch, end=\" \")\n",
    "    avg_loss = []\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        avg_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_history.append(np.mean(avg_loss))\n",
    "    print(f\" {loss.item():.2f},\", end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 - Precision: 0.88, Recall: 0.00\n",
      "Class 1 - Precision: 0.00, Recall: 0.00\n",
      "Class 2 - Precision: 0.09, Recall: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aatan\\Documents\\Github\\cryptotradr_py38\\cryptotradr\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate precision and recall for each class\n",
    "precision = precision_score(all_labels, all_predictions, average=None)\n",
    "recall = recall_score(all_labels, all_predictions, average=None)\n",
    "\n",
    "# Print precision and recall for each class\n",
    "for i in range(len(precision)):\n",
    "    print(f'Class {i} - Precision: {precision[i]:.2f}, Recall: {recall[i]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# custom loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, beta=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.alpha = alpha  # Interpolation factor for combining losses\n",
    "        self.beta = beta  # Balancing factor between false positives and false negatives for class 2\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        # Standard CrossEntropyLoss\n",
    "        ce_loss = self.cross_entropy_loss(outputs, targets)\n",
    "\n",
    "        # Custom loss focusing on label 2 (both false positives and false negatives)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        label_2_probs = probabilities[:, 2]\n",
    "\n",
    "        # Penalize false positives for label 2\n",
    "        non_label_2_mask = (targets != 2)\n",
    "        false_positives = label_2_probs * non_label_2_mask.float()\n",
    "\n",
    "        # Penalize false negatives for label 2\n",
    "        label_2_mask = (targets == 2)\n",
    "        false_negatives = (1 - label_2_probs) * label_2_mask.float()\n",
    "\n",
    "        # Combined custom loss for label 2\n",
    "        custom_loss = self.beta * false_positives.sum() + (1 - self.beta) * false_negatives.sum()\n",
    "\n",
    "        # Combined loss\n",
    "        combined_loss = (1 - self.alpha) * ce_loss + self.alpha * custom_loss\n",
    "        return combined_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X = torch.tensor(training_X, dtype=torch.float32).to(device)\n",
    "y = torch.tensor(train_data_y_discrete, dtype=torch.long).to(device)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, shuffle=True)\n",
    "\n",
    "# Create DataLoader for training and testing sets\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 2000\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model and move it to the selected device\n",
    "input_size = 14\n",
    "model = MLPClassifierPyTorch(input_size).to(device)\n",
    "\n",
    "criterion = CombinedLoss(alpha=0.5,beta=0.5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  27.41, \n",
      " 21.67,  24.16,  22.40,  22.10,  22.33,  22.85,  19.55,  26.41,  25.13, 10  19.03, \n",
      " 19.54,  23.34,  25.63,  24.36,  22.59,  20.83,  23.11,  28.18,  22.85, 20  18.01, \n",
      " 28.69,  23.88,  22.09,  25.90,  21.55,  24.87,  22.83,  23.35,  26.16, 30  25.38, \n",
      " 24.13,  25.88,  25.90,  27.16,  20.57,  23.60,  24.62,  26.42,  23.60, 40  23.36, \n",
      " 23.12,  22.84,  23.33,  23.10,  28.18,  22.31,  20.57,  23.61,  25.65, CPU times: total: 38.9 s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training loop\n",
    "loss_history = []\n",
    "for epoch in range(50):\n",
    "    if epoch%10==0:\n",
    "        print(epoch, end=\" \")\n",
    "    avg_loss = []\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        avg_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_history.append(np.mean(avg_loss))\n",
    "    print(f\" {loss.item():.2f},\", end=\" \")\n",
    "    if epoch%10==0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 - Precision: 0.80, Recall: 1.00\n",
      "Class 1 - Precision: 0.00, Recall: 0.00\n",
      "Class 2 - Precision: 0.00, Recall: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate precision and recall for each class\n",
    "precision = precision_score(all_labels, all_predictions, average=None,zero_division=0)\n",
    "recall = recall_score(all_labels, all_predictions, average=None,zero_division=0)\n",
    "\n",
    "# Print precision and recall for each class\n",
    "for i in range(len(precision)):\n",
    "    print(f'Class {i} - Precision: {precision[i]:.2f}, Recall: {recall[i]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
